{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "import seaborn as sns\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>invasive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  invasive\n",
       "0     1         0\n",
       "1     2         0\n",
       "2     3         1\n",
       "3     4         0\n",
       "4     5         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_labels.invasive.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2295 images\n"
     ]
    }
   ],
   "source": [
    "train_images = glob.glob('data/train/*.jpg')\n",
    "print('Found {} images'.format(len(train_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(train_images), 224, 224, 3))\n",
    "assert X.shape[0] == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_images)):\n",
    "    filename = os.path.join('data', 'train', '{}.jpg'.format(i + 1))\n",
    "    img = image.load_img(filename, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    assert x.shape == (224, 224, 3)\n",
    "    X[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_6 (Sequential)    (None, 1)                 6423041   \n",
      "=================================================================\n",
      "Total params: 21,137,729.0\n",
      "Trainable params: 21,137,729.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False,\n",
    "                  input_shape=(224, 224, 3))\n",
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Model(\n",
    "    inputs=base_model.input,\n",
    "    outputs=add_model(base_model.output))\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizers.SGD(lr=1E-4, momentum=0.9),\n",
    "    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "53/53 [==============================] - 3107s - loss: 0.6480 - acc: 0.8137 - val_loss: 0.2228 - val_acc: 0.9129\n",
      "CPU times: user 5h 9min 29s, sys: 19min 46s, total: 5h 29min 16s\n",
      "Wall time: 51min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "base_model = VGG16(weights='imagenet')\n",
    "\n",
    "x = base_model.get_layer('block5_pool').output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(X_train, y_train, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 321s    \n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22284476349993451, 0.91289198481662759]\n"
     ]
    }
   ],
   "source": [
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model.compile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(np.round(predictions[:10]).ravel().astype(int), y_test[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.round(predictions).ravel().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[315   7]\n",
      " [ 43 209]]\n"
     ]
    }
   ],
   "source": [
    "true_pos = ((pred == 1) & (y_test == 1)).sum()\n",
    "true_neg = ((pred == 0) & (y_test == 0)).sum()\n",
    "false_pos = ((pred == 1) & (y_test == 0)).sum()\n",
    "false_neg = ((pred == 0) & (y_test == 1)).sum()\n",
    "confusion = np.array([[true_pos, false_pos], [false_neg, true_neg]])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dd16ac88>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD3CAYAAAC+eIeLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dccc5588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
